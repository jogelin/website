---
title: "ğŸ¤– AI-Powered SDLC: Building an AI Framework for Developer Experience"
subtitle: "A practical guide to integrating AI across your Software Development Lifecycle"
publishedAt: 2025-01-13
coverImage: /blog/covers/ai-powered-sdlc-building-an-ai-framework-for-developer-experience.png
tags:
  - ai
  - developer-experience
  - nx
  - sdlc
  - architecture
  - ci-cd
author:
  name: Jonathan Gelin
  profilePicture: /avatar.png
type: article
draft: false
---

import UrlEmbed from "../../components/embeds/UrlEmbed.astro";
import WantToGoFurther from "../../components/embeds/WantToGoFurther.astro";

In large organizations, we invest a lot in engineering foundations: standards, best practices, tooling, documentation. But even when everything is in place to help teams, there's **no guarantee** it will actually be followed â€” or maintained over time. Turnover, habits, priorities, budget constraintsâ€¦ the list of reasons is long.

Since the rise of AI, I've been genuinely excited because I see real solutions to this challenge. What excites me the most is the idea of adding a layer on top of these foundations to **facilitate their adoption** by teams. In the same way automated tests validate your code, I really like the idea that your specs, your documentation, and your architectural rules can **validate your way of working through AI**. It also helps keeping codebases aligned with the latest standards over time.

![AI as a Bridge](/blog/images/ai-sdlc/02-ai-layer.png)

That said, there is one big pain point: **AI fatigue**.

Some time ago, people were talking a lot about JavaScript fatigue. Personally, I always found it exciting to discover new frameworks and architectures and try to understand what could be the next best one. AI brings a similar level of excitement â€” but to be honest, it is **impossible to follow everything**. New tools, new models, new workflows appear almost every week.

Still, we have to start somewhere.

In this article, I wanted to structure everything I've been learning about AI in software development â€” as much for myself as for you. I'll list **concrete use cases** where AI can improve the **Developer Experience**, increase productivity, and â€” maybe more importantly â€” **improve quality in a sustainable way**.

---

## ğŸ§± Core Concepts

To understand how AI transforms the SDLC, let's first look at the key layers that make it effective.

![The AI-Powered Developer Experience Stack](/blog/images/ai-sdlc/19-stacked-concepts.png)

### ğŸ—ï¸ Engineering Foundations

AI needs **trusted, structured knowledge** to be effective. The more organized your foundations, the more powerful AI becomes.

Key sources include:

- **Codebase** â€” Your actual code, patterns, and implementations
- **Architecture** â€” System design, boundaries, constraints, ADRs
- **Design System** â€” UI components, tokens, accessibility standards
- **Dependency Graph** â€” Project relationships and impact analysis
- **CI/CD Signals** â€” Build history, failures, flaky tests, bottlenecks
- **Documentation** â€” Conventions, onboarding guides, runbooks
- **Methodologies** â€” Agile, Scrum, SAFe, workflows, team rituals, definition of done

Organizations with clear boundaries, ownership, and conventions naturally benefit more from AI â€” because AI has a *map*, not just files.

> ğŸ’¡ **Nx as a Foundation**: Nx provides structured, queryable knowledge about your workspace â€” project graph, generators, affected analysis â€” that AI tools can leverage directly via MCP.

### ğŸ§  AI Orchestration

The **AI Orchestration** is the central piece of your AI-powered development workflow. It combines the **AI Framework** (your organizational knowledge) with **AI Tooling** (the interfaces developers use).

#### AI Framework

The AI Framework is a structured collection of knowledge, rules, and behaviors that define how your organization works. It's not a product you buy â€” it's something you **build and maintain internally**, tailored to your specific context.

Without an AI Framework, every AI interaction starts from zero. The AI doesn't know your conventions, your architecture decisions, your preferred patterns. With an AI Framework, the AI becomes a **team member who has read all the documentation** and actually remembers it.

![AI Framework Components](/blog/images/ai-sdlc/18-ai-framework-contents.png)

| Component | Description | Example |
|-----------|-------------|---------|
| **Agents** | Specialized personas with specific expertise | PM Agent, Frontend Agent, QA Agent |
| **Skills** | Auto-loaded context based on task type | Design system skill, API conventions skill |
| **MCPs** | Connections to external data and tools | Nx MCP, Jira MCP, Git MCP |
| **Prompts** | Reusable instructions for common tasks | "When generating a component, always use our Button primitive" |
| **Templates** | Standard structures for common outputs | PR template, ADR template, user story format |
| **Rules** | Architectural constraints and conventions | "Feature modules must not import from other features" |
| **Examples** | Reference implementations | "Here's how we structure a typical service" |

Your AI Framework is a **living artifact**. Every improvement you make benefits all use cases immediately:

- Discovered a better prompt for code reviews? Add it to the framework.
- New architectural pattern adopted? Update the skills.
- Common mistake happening? Add a rule to prevent it.

This creates a **compound effect**: the more you invest in your AI Framework, the more value you extract from every AI interaction.

![Compound Effect](/blog/images/ai-sdlc/16-compound-effect.png)

#### AI Tooling

The AI Framework is consumed by multiple tools. Whatever tool developers use, they get the same AI behavior because they share the same framework.

![AI Tooling Categories](/blog/images/ai-sdlc/20-ai-tooling-categories.png)

**1. In-Context Coding Assistants** â€” *"AI sitting next to me while I type."*

IDE and editor integrations that help while you actively write code: code completion, inline refactoring, local reasoning over open files.

**2. Conversational & Reasoning Tools** â€” *"AI I talk to when I need to think."*

Chat interfaces for understanding and decision-making: code explanation, debugging discussions, architecture reasoning, design exploration.

**3. Automation & Agentic Tools** â€” *"AI that does work for me."*

CLIs and background agents that execute actions across the codebase: repo-wide refactors, scaffolding, feature implementation from prompts.

**4. Quality, Governance & Delivery Assistants** â€” *"AI that watches the system."*

PR, CI/CD, and governance integrations focused on control and consistency: AI code review, test generation, CI failure diagnosis, architecture enforcement.

---

## ğŸ¯ Developer Experience Across the SDLC

How does AI improve Developer Experience at each phase of the Software Development Lifecycle?

![SDLC Phases with AI Framework](/blog/images/ai-sdlc/08-sdlc-phases.png)

### ğŸ“‹ Specify

AI supports Product Owners, Business Analysts, and developers in writing and refining requirements before any code is written.

![AI in Specification Phase](/blog/images/ai-sdlc/21-specify-phase.png)

**ğŸ“ Task Writing** â€” Define your methodology (Agile, Scrum, SAFe) in your AI Framework with templates and acceptance criteria patterns. AI then writes tasks from rough descriptions, splits large stories, suggests acceptance criteria, and identifies gaps.

**ğŸ“Š Backlog Organization** â€” AI analyzes your backlog to group related items, identify duplicates, suggest priorities based on dependencies, and flag stories that are too large or vague.

**ğŸ¤ Interview Mode** â€” Instead of writing specs from scratch, AI interviews you about technical details, UX decisions, and edge cases, then generates a complete specification.

#### Enablers

**ğŸ“ Prompt Engineering Fundamentals**

The model isn't wrong â€” **the prompt is**. Whatever you want AI to achieve, you need prompts or specs it can understand and apply. Effective prompts include:

- **Role**: Who should the AI act as?
- **Goal**: What outcome do you want?
- **Tasks**: Step-by-step actions to achieve the goal
- **Context**: Background information about your environment
- **Examples**: Concrete samples that guide interpretation

> ğŸ“š **Recommended Reading**: Google's free ebook "Prompting guide 101: A quick-start handbook for effective prompts"

<UrlEmbed url="https://workspace.google.com/learning/content/gemini-prompt-guide" />

**ğŸ“„ Spec-Driven Development**

Spec-Driven Development (SDD) flips the traditional approach: instead of writing code then documentation, you **write the specification first** and let AI implement it.

<UrlEmbed url="https://github.blog/ai-and-ml/generative-ai/spec-driven-development-with-ai-get-started-with-a-new-open-source-toolkit/" />

<UrlEmbed url="https://martinfowler.com/articles/exploring-gen-ai/sdd-3-tools.html" />

**ğŸ™ï¸ AI-Assisted Spec Generation (Interview Mode)**

One powerful technique is asking AI to **interview you** to generate a complete spec. Instead of writing everything yourself, you have a conversation:

```markdown
read this @SPEC.md and interview me in detail using the AskUserQuestionTool about literally anything: technical implementation, UI & UX, concerns, tradeoffs, etc. but make sure the questions are not obvious

be very in-depth and continue interviewing me continually until it's complete, then write the spec to the file
```

<UrlEmbed url="https://x.com/trq212/status/2005315275026260309" />

**ğŸ¢ The BMAD Method**

For enterprise-scale projects, the **BMAD Method** (Business Model Architecture Development) provides a structured approach with specialized AI agents at each phase:

![BMAD Method Flow](/blog/images/ai-sdlc/10-bmad-method.png)

| Agent | Responsibility |
|-------|----------------|
| **Business Analyst** | Requirements gathering, stakeholder needs |
| **Product Manager** | Prioritization, roadmap, user stories |
| **Architect** | System design, technical decisions |
| **Developer** | Implementation details, code structure |
| **QA** | Test scenarios, edge cases, validation |

Each agent has specific skills, context, and output formats tailored to their role. The output of one agent feeds into the next.

<UrlEmbed url="https://docs.bmad-method.org/" />

### ğŸ¨ Design

AI helps design solutions that align with your existing architecture and patterns.

![AI in Design Phase](/blog/images/ai-sdlc/22-design-phase.png)

**ğŸ—ï¸ Architecture Design** â€” AI generates component diagrams, sequence diagrams, data models, API contracts (OpenAPI), and ADRs. When connected to your AI Framework, designs follow your established patterns â€” not generic solutions.

**ğŸ¯ Specifications** â€” From a high-level idea, AI produces detailed technical requirements, API contracts, data models, integration points, and non-functional requirements.

**ğŸ¨ UI/UX Design** â€” Generate mockups from descriptions, create variants for review, apply design tokens from your design system, and ensure accessibility from the start. Tools like v0.dev and Figma AI make this increasingly accessible.

**ğŸ“š Documentation** â€” AI produces documentation that stays synchronized: architecture overviews from code, API docs from OpenAPI specs, READMEs, and onboarding guides â€” all generated from source rather than manually maintained.

> ğŸ’¡ Include your design system (components, tokens, guidelines) and ADRs in your AI Framework so AI respects past decisions.

#### Enablers

**ğŸ“‹ Architecture Decision Records (ADRs)**

Capture design decisions in a structured format AI can understand and reference:

```markdown
# ADR-001: Use Event Sourcing for Order Management

## Status: Accepted

## Context
We need to track all changes to orders for audit and replay capabilities.

## Decision
We will use Event Sourcing pattern with Kafka as the event store.

## Consequences
- Full audit trail available
- Increased complexity in queries
- Need for event versioning strategy
```

When ADRs are part of your AI Framework, new designs automatically respect past decisions.

**ğŸ¨ Design System Integration**

Your AI Framework should include your design system:
- Component library documentation
- Design tokens (colors, spacing, typography)
- Usage guidelines and patterns
- Accessibility requirements

> ğŸ’¡ **Storybook** documentation can be exposed to AI, ensuring generated components match your established UI patterns.

### ğŸ’» Develop

From autocomplete to full agentic coding, AI transforms how developers write code.

![AI in Development Phase](/blog/images/ai-sdlc/23-develop-phase.png)

**âš¡ Contextualized Code Generation** â€” Beyond generic autocomplete, AI with your AI Framework generates code following your naming conventions, established patterns, correct imports, and module boundaries. Generic AI creates new utilities; contextualized AI uses your existing `@org/utils`.

**ğŸ” Codebase Understanding** â€” AI helps navigate large codebases: "What does this service do?", "What calls this function?", "What will break if I change this?" Nx MCP provides project graph context for accurate impact analysis.

**ğŸ”„ Legacy Modernization** â€” AI accelerates codebase modernization: pattern detection, automated codemods, incremental file-by-file transformation, and continuous alignment with latest standards.

**ğŸ¤– Agentic Tasks** â€” Delegate multi-step tasks: "Create a new feature module with service, component, and tests" or "Refactor this class to use the new API pattern." AI plans, executes, and validates.

#### Enablers

**ğŸ’» AI-Powered Editors**

Developers need editors with AI coding assistant capabilities. The AI Framework works across all of these â€” your skills and rules apply regardless of editor choice.

- **AI-native editors** provide deep integration: [Cursor](https://cursor.sh/), [Windsurf](https://codeium.com/windsurf), [Google Antigravity](https://antigravity.google/)
- **Extensions** bring AI to existing workflows: [GitHub Copilot](https://github.com/features/copilot), [JetBrains AI](https://www.jetbrains.com/ai/)

**âŒ¨ï¸ Command Line Interfaces**

CLIs are essential for automation, scripting, and CI integration. Three major players have emerged:

**â†’ [Claude Code](https://docs.anthropic.com/en/docs/claude-code)** â€” Pioneered concepts like **MCP** (Model Context Protocol) and **Skills** that are becoming industry standards. Its plugin system maps directly to the AI Framework concept, making it ideal for organizational standardization.

- **MCP (Model Context Protocol)** â€” Connect AI to external data sources: project graphs, issue trackers, git history, databases. Nx MCP exposes workspace structure, generators, and affected analysis.
- **Skills** â€” Auto-loaded context files based on task type. When working on a component, the design-system skill loads. When on an API, the api-conventions skill loads.
- **Agents** â€” Specialized personas with specific expertise that can be invoked for complex tasks (PM Agent, QA Agent, etc.)
- **Prompts** â€” Reusable instructions for common tasks that ensure consistency.
- **Commands** â€” Custom slash commands (`/commit`, `/review`, `/deploy`) that trigger predefined workflows with consistent behavior.
- **Hooks** â€” Event-driven automation triggered at specific points (PreToolUse, PostToolUse, Stop). Use them to validate actions, enforce rules, or run checks automatically.
- **LSP (Language Server Protocol)** â€” IDE integration that brings Claude Code capabilities directly into your editor with real-time suggestions and inline assistance.

<UrlEmbed url="https://docs.anthropic.com/en/docs/claude-code/skills" />

<UrlEmbed url="https://docs.anthropic.com/en/docs/claude-code/plugins-reference#plugin-components-reference" />

**â†’ [Gemini CLI](https://github.com/google-gemini/gemini-cli)** â€” Google's entry adopts a similar approach with MCP support, bringing Gemini models to the command line with familiar conventions.

<UrlEmbed url="https://geminicli.com/docs/" />

**â†’ [OpenCode](https://opencode.ai/)** â€” A really promising open-source alternative offering compatibility with multiple LLM providers (OpenAI, Anthropic, Google, local models). Great option if you want provider flexibility or need to run local models.

<UrlEmbed url="https://opencode.ai/" />

> ğŸ”® **Future prediction**: The line between editors and CLIs is blurring. We may move toward prompt-driven development where the interface matters less than the AI Framework powering it.

**ğŸ”— Agent Orchestration Patterns**

For complex workflows, multiple specialized agents can collaborate:

**â†’ Ralph Wiggum** (Claude Code Plugin) â€” An orchestration layer that coordinates multiple Claude Code instances for complex, multi-part tasks.

<UrlEmbed url="https://github.com/anthropics/claude-code/tree/main/plugins/ralph-wiggum" />

**â†’ Auto-Claude** â€” Automated Claude Code workflows that can run sequences of tasks with checkpoints and validation.

<UrlEmbed url="https://github.com/AndyMik90/Auto-Claude" />

**â†’ Get Shit Done** â€” A task-focused orchestration tool that breaks down complex objectives into actionable steps with AI assistance.

<UrlEmbed url="https://github.com/glittercowboy/get-shit-done" />

### âœ… Validate

AI can be both the creator and the validator â€” a powerful feedback loop where AI checks its own work and the work of humans.

![AI in Validation Phase](/blog/images/ai-sdlc/24-validate-phase.png)

**ğŸ“ PR Automation** â€” AI analyzes diffs and commits to generate PR descriptions, list affected components, highlight risks, and fill templates. No more empty or "fixes stuff" descriptions.

**ğŸ” Code Review** â€” AI reviews PRs for pattern violations, security issues, performance concerns, and missing test coverage. Not a replacement for human review â€” a first pass that lets humans focus on design and logic.

**ğŸš§ Quality Gates** â€” Automated checks block PRs violating module boundaries, unapproved dependencies, missing docs, or accessibility requirements.

**ğŸ”§ Self-Healing CI** â€” When CI fails, AI reads error logs, understands context, proposes fixes, and opens PRs. The flow is simple: CI runs and fails â†’ AI agent analyzes error logs with codebase context â†’ Fix is proposed as PR comment or auto-applied. Ask your CI questions in natural language: "Show me failed builds from last week."

#### Enablers

**ğŸ”§ Nx Cloud Self-Healing**

**Nx** implements the self-healing pattern, connecting AI analysis with your project graph for accurate root cause detection.

<UrlEmbed url="https://nx.dev/blog/nx-self-healing-ci" />

**ğŸ›ï¸ Architecture Conformance**

**â†’ Nx Conformance** â€” Define and enforce architectural rules across your codebase: module boundaries, dependency constraints, naming conventions, and coding standards. AI can leverage these rules to ensure generated code respects your architecture.

<UrlEmbed url="https://nx.dev/docs/enterprise/conformance" />

### ğŸš€ Release

AI automates communication and coordination around releases.

![AI in Release Phase](/blog/images/ai-sdlc/25-release-phase.png)

**ğŸ“‹ Changelog Generation** â€” AI analyzes commits and PRs to generate user-friendly changelogs, technical release notes, breaking change summaries, and migration guides. No more manually writing "what changed."

**ğŸ“£ Release Communication** â€” AI prepares stakeholder announcements, customer-facing updates, and team briefings â€” each tailored to its audience.

**âœ… Deployment Validation** â€” Pre-deployment checklists, configuration validation, environment comparison, and rollback decision support.

**ğŸš¨ Incident Analysis** â€” When issues occur post-deployment, AI correlates with recent changes, analyzes logs, and suggests root causes or rollback.

> ğŸ’¡ Use **conventional commits** (`feat:`, `fix:`, `breaking:`) so AI can automatically categorize changes and determine version bumps.

#### Enablers

**ğŸ“ Conventional Commits**

Structured commit messages enable AI to understand changes:

```
feat(checkout): add express payment option
fix(auth): resolve token refresh race condition
breaking(api): remove deprecated v1 endpoints
```

With this structure, AI can automatically categorize and summarize changes.

**ğŸ“¦ Automated Release Management**

**â†’ Nx Release** â€” Integrated release management for Nx workspaces with version inference, changelog generation, and publishing. Combines conventional commits with project graph awareness for intelligent versioning across monorepos.

<UrlEmbed url="https://nx.dev/features/manage-releases" />

### ğŸ”„ Maintain

Software is never "done." AI helps maintain, improve, and evolve codebases continuously.

![AI in Maintenance Phase](/blog/images/ai-sdlc/26-maintain-phase.png)

**ğŸ”§ Automated Refactoring** â€” AI performs large-scale refactoring: rename patterns, extract shared code, update APIs, remove deprecated code. With project graph context, AI understands impact and validates changes.

**â¬†ï¸ Automatic Upgrades** â€” When dependencies release new versions, AI reads changelogs, identifies breaking changes, proposes migrations, and validates with tests. Transform "dreaded upgrade sprint" into continuous updates.

**ğŸ“Š Tech Debt Analysis** â€” AI identifies and quantifies tech debt: outdated patterns, missing coverage, complex code. Instead of "we have tech debt," you get a prioritized list with effort estimates.

**ğŸŒ Cross-Repository Intelligence** â€” For large organizations: understand dependencies between repos, coordinate spanning changes, ensure consistency. Nx Polygraph (coming soon) extends AI context across repositories.

#### Enablers

**ğŸ” Code Health & Tech Debt Analysis**

**â†’ SonarQube / SonarCloud** â€” Continuous code quality inspection that identifies security vulnerabilities, code smells, and tech debt. Provides quantified metrics and trends that AI can use to prioritize refactoring efforts.

<UrlEmbed url="https://www.sonarsource.com/products/sonarcloud/" />

---

## ğŸŒ Cross-Cutting Capabilities

Some AI capabilities span the entire SDLC.

**ğŸ“š Living Documentation** â€” Documentation that updates itself: API docs from code, architecture diagrams from project graph, guides reflecting current patterns. When code changes, documentation follows.

**ğŸ“ Accelerated Onboarding** â€” New team members ask questions about the codebase, get architecture tours, and pair program with AI. The AI Framework ensures they learn your patterns, not generic ones.

**ğŸ’¬ Automated Support** â€” AI answers developer questions from documentation and resolved issues. Common questions get instant responses; only new issues reach the support team.

**ğŸ”’ Security & Governance** â€” Include security rules in your AI Framework: approved authentication patterns, required headers, prohibited practices. Track ROI with metrics on time saved and error rates.

> ğŸ’¡ **Start small, prove value, then expand.** Training developers on prompting and building trust through gradual adoption is key to successful AI adoption.

#### Enablers

**ğŸ“– Codebase Understanding & Documentation**

**â†’ CodeWiki** (Google) â€” An AI-powered knowledge base that understands your entire codebase. Ask questions in natural language, get contextual answers with code references, and maintain living documentation that stays synchronized with your code.

<UrlEmbed url="https://codewiki.google/" />

**ğŸ”§ CI/CD Intelligence & Optimization**

**â†’ Nx Cloud** â€” Connects AI analysis with your project graph for intelligent CI/CD. Provides self-healing CI, pipeline analytics, task distribution insights, and cross-repository intelligence. Essential for understanding build patterns and optimizing delivery.

<UrlEmbed url="https://nx.dev/nx-cloud" />

---

## ğŸ Getting Started

You don't need to implement everything at once.

![Getting Started Roadmap](/blog/images/ai-sdlc/14-getting-started-roadmap.png)

**Pick one use case with clear ROI:**
- CI painful? â†’ Self-healing CI
- Onboarding slow? â†’ Codebase Q&A
- Review bottleneck? â†’ Automated review

**Build incrementally:**
1. **Foundation** â€” Create `/skills` structure, document conventions, configure MCP
2. **First Use Case** â€” Implement, gather feedback, refine
3. **Expand** â€” Add skills, agents, and MCPs progressively

**Measure what matters:** Time to first PR, CI resolution time, review turnaround, developer satisfaction.

---

## ğŸ™‚ Last Thoughts

AI is transforming every phase of the Software Development Lifecycle â€” from specification to maintenance. But the real power isn't in individual tools; it's in building an **AI Framework** that encodes your organization's standards, patterns, and knowledge. When AI understands your context, every interaction becomes more valuable.

**Key takeaways:**

1. **AI Framework is central** â€” Build it once, benefit everywhere. Your skills, rules, and MCPs work across all tools.
2. **Start with one use case** â€” Prove value before expanding. Pick your biggest pain point and solve it well.
3. **Tools are interchangeable** â€” Claude Code, Gemini CLI, Cursor, Copilot â€” your framework powers them all.
4. **Compound effect** â€” Every improvement to your framework benefits all use cases immediately.
5. **AI augments, not replaces** â€” Human judgment remains essential. AI handles the repetitive; you focus on the creative.

The organizations that invest in their AI Framework today will see compounding returns in Developer Experience, code quality, and delivery speed.

The question isn't whether to adopt AI in your SDLC â€” it's **how fast you can build the framework** to make it truly effective.

---

<WantToGoFurther />
